
exp_name: "N12S1_CleanRL"
seed: 5031997
torch_deterministic: true
cuda: false
track: true
wandb_project_name: "N12S1"
capture_video: false
policy_name: "IA-ARPPO"
save_models: true
notes: For Clean RL based standard PPO implementation (discounted rewards)


env_json_path: "/JSON/Environment/ServerAllocation/N12/N12S1.json"
total_timesteps: 5.0e+7
learning_rate: 1.0e-4
num_envs: 1
num_steps: 512
anneal_lr: false
gamma: 1.0
gae_lambda: 0.95
num_minibatches: 4
update_epochs: 10
norm_adv: true
clip_coef: 0.2
clip_vloss: false
ent_coef: 0.01
vf_coef: 0.5
max_grad_norm: 0.5
target_kl: ~
alpha: 0.1
nu: -0.1
temperature: 0.5
learn_temperature: true
intervention_penalty: 0.00

hidden_size: ~
hidden_depth: ~

critic_hidden_dims: [4, 128 ]
actor_hidden_dims: [4, 128]

reward_scale: .001
obs_scale: 50

int_thresh: 25

window_size: 10000



