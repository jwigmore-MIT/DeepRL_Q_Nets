
exp_name: "M2A3_CleanRL"
env_type: "ServerAllocation"
obs_links: true
seed: 5031998
torch_deterministic: true
cuda: true
track: true
test: true
wandb_project_name: "ServerAllocation_M2A3-O"
capture_video: false
policy_name: "Q-IA-ARPPO"
save_models: true
notes: For Clean RL based standard PPO implementation (discounted rewards)


env_json_path: "/JSON/Environment/ServerAllocation/M2A3.json"
total_timesteps: 3.0e+6
learning_rate: 3.0e-4
num_envs: 1
num_steps: 512
anneal_lr: false
gamma: 1.0
gae_lambda: 0.95
num_minibatches: 4
update_epochs: 10
norm_gaes: true
clip_coef: 0.2
clip_vloss: false
ent_coef: 0.01
vf_coef: 0.5
adv_coef: 0.5
max_grad_norm: 0.5
target_kl: ~
alpha: 0.2
nu: -0.1
temperature: 0.3
learn_temperature: true
intervention_penalty: 0.00

shared_critic_dims: [1, 64]
separate_critic_dims: [1, 64]
actor_dims: [2, 64]

reward_scale: .001
obs_scale: 50

int_thresh: 10

apply_mask: true
stable_policy: MWCQ

window_size: 10000

do_eval: false
eval_freq: 100000
eval_steps: 1.0e+5
test_steps: 1.0e+5

learning_steps: 5.0e+5





